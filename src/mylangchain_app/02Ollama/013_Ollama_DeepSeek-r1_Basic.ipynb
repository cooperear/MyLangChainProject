{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - langchain\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n",
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - langchain-ollama\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n",
      "Using version ^0.3.29 for langchain-community\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "Package operations: 15 installs, 0 updates, 0 removals\n",
      "\n",
      "  - Installing frozenlist (1.7.0)\n",
      "  - Installing multidict (6.6.4)\n",
      "  - Installing mypy-extensions (1.1.0)\n",
      "  - Installing propcache (0.3.2)\n",
      "  - Installing aiohappyeyeballs (2.6.1)\n",
      "  - Installing aiosignal (1.4.0)\n",
      "  - Installing attrs (25.3.0)\n",
      "  - Installing typing-inspect (0.9.0)\n",
      "  - Installing marshmallow (3.26.1)\n",
      "  - Installing yarl (1.20.1)\n",
      "  - Installing aiohttp (3.12.15)\n",
      "  - Installing dataclasses-json (0.6.7)\n",
      "  - Installing pydantic-settings (2.10.1)\n",
      "  - Installing httpx-sse (0.4.1)\n",
      "  - Installing langchain-community (0.3.29)\n",
      "\n",
      "Writing lock file\n"
     ]
    }
   ],
   "source": [
    "!poetry add  langchain\n",
    "!poetry add langchain-ollama\n",
    "!poetry add langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬 Ollama로 설치한 deepseek-r1:1.5b 모델을 사용하기\n",
    "##### ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'question': 'LangChain을 설명해줘', 'text': '## LangChain 설명: LLM 활용을 위한 프레임워크\\n\\nLangChain은 대규모 언어 모델(LLM)과 연동하여 다양한 애플리케이션을 구축할 수 있도록 돕는 **프레임워크**입니다. LLM을 단순히 텍스트 생성 도구로 사용하는 것을 넘어, LLM을 활용한 복잡한 작업 (질의응답, 문서 요약, 코드 생성 등)을 쉽고 효율적으로 구현할 수 있도록 지원합니다.\\n\\n**핵심 개념:**\\n\\n* **LLM과의 연결 (LLM Chain):** LangChain의 핵심은 LLM을 단순히 텍스트를 생성하는 모델이 아닌, **체인 (Chain)** 형태로 연결하여 유기적인 워크플로우를 구축하는 것입니다.  이 체인은 여러 컴포넌트들을 연결하여, 하나의 목표를 달성하기 위한 일련의 과정을 정의합니다.\\n* **컴포넌트:** LangChain은 LLM 외에도 다양한 컴포넌트들을 제공합니다.  이 컴포넌트들을 조합하여 다양한 체인을 구성할 수 있습니다. 주요 컴포넌트는 다음과 같습니다.\\n    * **Models:** OpenAI, Cohere, Hugging Face 등 다양한 LLM과의 연동을 지원합니다.\\n    * **Prompts:** LLM에게 전달할 프롬프트를 관리하고 최적화하는 데 사용됩니다.\\n    * **Chains:**  여러 컴포넌트들을 연결하여 복잡한 워크플로우를 정의합니다. (예: 질문 응답 체인, 문서 요약 체인)\\n    * **Indexes:**  문서 데이터 (PDF, 텍스트 파일 등)를 효과적으로 구조화하고 검색하는 데 사용됩니다.  LLM이 정보를 찾아 활용하는 데 도움이 됩니다.\\n    * **Memory:** LLM의 컨텍스트를 유지하고 대화 기록을 관리합니다. (예: 대화형 챗봇 구축)\\n    * **Agents:** LLM을 사용하여 의사 결정을 내리고 특정 작업을 수행하도록 합니다.\\n\\n**LangChain의 주요 특징:**\\n\\n* **모듈화:** 컴포넌트 기반으로 구성되어, 필요에 따라 유연하게 조합하여 다양한 애플리케이션을 구축할 수 있습니다.\\n* **다양한 LLM 지원:**  OpenAI, Cohere, Hugging Face 등 다양한 LLM을 지원합니다.\\n* **활발한 커뮤니티:**  활발한 커뮤니티 지원과 다양한 튜토리얼 및 예제 코드 제공으로 학습 및 개발을 용이하게 합니다.\\n* **상업적 활용 가능:**  상업적 프로젝트에도 활용 가능합니다.\\n\\n**LangChain을 사용하여 할 수 있는 것들:**\\n\\n* **질의응답 (Question Answering):** 문서, 웹 페이지, 데이터베이스 등 다양한 정보 소스에 대한 질문에 답변합니다.\\n* **문서 요약 (Document Summarization):** 긴 문서의 내용을 요약합니다.\\n* **코드 생성 (Code Generation):**  자연어 설명을 기반으로 코드를 생성합니다.\\n* **챗봇 (Chatbots):**  대화형 챗봇을 구축합니다.\\n* **데이터 분석 (Data Analysis):**  자연어 질문을 통해 데이터 분석을 수행합니다.\\n* **에이전트 (Agents):**  LLM을 사용하여 복잡한 작업을 수행하는 에이전트를 구축합니다.\\n\\n**자세한 정보:**\\n\\n* **LangChain 공식 웹사이트:** [https://www.langchain.com/](https://www.langchain.com/)\\n* **LangChain GitHub 저장소:** [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\\n\\n---\\n\\n이 설명이 LangChain에 대한 이해를 돕는 데 도움이 되기를 바랍니다.  궁금한 점이 있다면 언제든지 질문해주세요.'}\n",
      "## LangChain 설명: LLM 활용을 위한 프레임워크\n",
      "\n",
      "LangChain은 대규모 언어 모델(LLM)과 연동하여 다양한 애플리케이션을 구축할 수 있도록 돕는 **프레임워크**입니다. LLM을 단순히 텍스트 생성 도구로 사용하는 것을 넘어, LLM을 활용한 복잡한 작업 (질의응답, 문서 요약, 코드 생성 등)을 쉽고 효율적으로 구현할 수 있도록 지원합니다.\n",
      "\n",
      "**핵심 개념:**\n",
      "\n",
      "* **LLM과의 연결 (LLM Chain):** LangChain의 핵심은 LLM을 단순히 텍스트를 생성하는 모델이 아닌, **체인 (Chain)** 형태로 연결하여 유기적인 워크플로우를 구축하는 것입니다.  이 체인은 여러 컴포넌트들을 연결하여, 하나의 목표를 달성하기 위한 일련의 과정을 정의합니다.\n",
      "* **컴포넌트:** LangChain은 LLM 외에도 다양한 컴포넌트들을 제공합니다.  이 컴포넌트들을 조합하여 다양한 체인을 구성할 수 있습니다. 주요 컴포넌트는 다음과 같습니다.\n",
      "    * **Models:** OpenAI, Cohere, Hugging Face 등 다양한 LLM과의 연동을 지원합니다.\n",
      "    * **Prompts:** LLM에게 전달할 프롬프트를 관리하고 최적화하는 데 사용됩니다.\n",
      "    * **Chains:**  여러 컴포넌트들을 연결하여 복잡한 워크플로우를 정의합니다. (예: 질문 응답 체인, 문서 요약 체인)\n",
      "    * **Indexes:**  문서 데이터 (PDF, 텍스트 파일 등)를 효과적으로 구조화하고 검색하는 데 사용됩니다.  LLM이 정보를 찾아 활용하는 데 도움이 됩니다.\n",
      "    * **Memory:** LLM의 컨텍스트를 유지하고 대화 기록을 관리합니다. (예: 대화형 챗봇 구축)\n",
      "    * **Agents:** LLM을 사용하여 의사 결정을 내리고 특정 작업을 수행하도록 합니다.\n",
      "\n",
      "**LangChain의 주요 특징:**\n",
      "\n",
      "* **모듈화:** 컴포넌트 기반으로 구성되어, 필요에 따라 유연하게 조합하여 다양한 애플리케이션을 구축할 수 있습니다.\n",
      "* **다양한 LLM 지원:**  OpenAI, Cohere, Hugging Face 등 다양한 LLM을 지원합니다.\n",
      "* **활발한 커뮤니티:**  활발한 커뮤니티 지원과 다양한 튜토리얼 및 예제 코드 제공으로 학습 및 개발을 용이하게 합니다.\n",
      "* **상업적 활용 가능:**  상업적 프로젝트에도 활용 가능합니다.\n",
      "\n",
      "**LangChain을 사용하여 할 수 있는 것들:**\n",
      "\n",
      "* **질의응답 (Question Answering):** 문서, 웹 페이지, 데이터베이스 등 다양한 정보 소스에 대한 질문에 답변합니다.\n",
      "* **문서 요약 (Document Summarization):** 긴 문서의 내용을 요약합니다.\n",
      "* **코드 생성 (Code Generation):**  자연어 설명을 기반으로 코드를 생성합니다.\n",
      "* **챗봇 (Chatbots):**  대화형 챗봇을 구축합니다.\n",
      "* **데이터 분석 (Data Analysis):**  자연어 질문을 통해 데이터 분석을 수행합니다.\n",
      "* **에이전트 (Agents):**  LLM을 사용하여 복잡한 작업을 수행하는 에이전트를 구축합니다.\n",
      "\n",
      "**자세한 정보:**\n",
      "\n",
      "* **LangChain 공식 웹사이트:** [https://www.langchain.com/](https://www.langchain.com/)\n",
      "* **LangChain GitHub 저장소:** [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\n",
      "\n",
      "---\n",
      "\n",
      "이 설명이 LangChain에 대한 이해를 돕는 데 도움이 되기를 바랍니다.  궁금한 점이 있다면 언제든지 질문해주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1 모델을 로드\n",
    "llm = Ollama(model=\"gemma3\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Q: {question}\\nA:\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 질문을 입력하고 모델의 응답을 받음\n",
    "question = \"LangChain을 설명해줘\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# 결과 출력\n",
    "print(type(response))\n",
    "print(response)\n",
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최신버전 LangChain에서는 ChatOllama와 RunnableSequence(prompt | llm) 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# prompt_template = PromptTemplate.from_template(\"Q: {question}\\nA:\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is Pyhon?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
