{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "네, AI 전문가로서 LangChain과 LangGraph에 대해 명확하고 이해하기 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "이 둘은 LLM(거대 언어 모델)을 활용하여 강력한 애플리케이션을 구축하기 위한 핵심 도구이지만, 서로 다른 목적과 구조를 가집니다.\n",
      "\n",
      "**한마디로 요약하자면:**\n",
      "\n",
      "*   **LangChain (랭체인):** LLM 애플리케이션을 만들기 위한 **'부품(LEGO 블록)'**과 그 부품들을 순서대로 연결하는 **'조립 설명서'**입니다.\n",
      "*   **LangGraph (랭그래프):** 여러 LLM 에이전트들이 서로 협력하거나, 복잡한 조건에 따라 작업 흐름을 바꾸는 **'지능적인 순서도(Flowchart)'**입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LangChain: LLM 애플리케이션의 기본 골격\n",
      "\n",
      "LangChain은 LLM을 단독으로 사용하는 것을 넘어, 다른 데이터 소스나 외부 도구와 연결하여 훨씬 더 유용한 애플리케이션을 만들 수 있도록 도와주는 **프레임워크**입니다. 마치 레고 블록처럼 다양한 기능(컴포넌트)을 제공하며, 이를 사슬(Chain)처럼 연결하여 원하는 기능을 구현합니다.\n",
      "\n",
      "#### LangChain의 핵심 구성 요소 (레고 블록들)\n",
      "\n",
      "1.  **Models:** GPT-4, Claude 등 다양한 LLM 모델을 쉽게 가져와 쓸 수 있게 해줍니다.\n",
      "2.  **Prompts:** LLM에 보낼 지시문(프롬프트)을 효과적으로 관리하고, 변수를 넣어 동적으로 생성하는 템플릿 기능을 제공합니다.\n",
      "3.  **Chains:** LangChain의 핵심 개념으로, 모델, 프롬프트, 다른 체인 등을 순차적으로 연결하여 하나의 작업 흐름을 만듭니다. (예: `사용자 질문` -> `프롬프트 템플릿` -> `LLM 호출` -> `결과 파싱`)\n",
      "4.  **Indexes & Retrievers:** PDF, DB 등 외부 데이터를 LLM이 이해할 수 있는 형태(벡터)로 만들고, 사용자의 질문과 관련된 부분을 효율적으로 찾아주는 기능입니다. **RAG(검색 증강 생성)**의 핵심 요소입니다.\n",
      "5.  **Agents & Tools:** LLM에게 '도구(Tool)'를 쥐여주는 것입니다. LLM이 단순히 텍스트만 생성하는 것을 넘어, 웹 검색, 계산기 사용, API 호출 등 실제 행동을 수행하게 만듭니다.\n",
      "6.  **Memory:** 대화의 맥락을 기억하게 하여, 이전 대화 내용을 바탕으로 더 자연스러운 답변을 생성하게 합니다.\n",
      "\n",
      "> **LangChain의 본질:** **정해진 순서(A → B → C)**에 따라 작업을 처리하는 데 매우 강력합니다. 하지만 작업 흐름이 복잡해지고, 중간 결과에 따라 다음 행동이 계속 바뀌어야 하는 경우에는 한계가 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. LangGraph: 복잡한 LLM 워크플로우를 위한 확장\n",
      "\n",
      "LangGraph는 LangChain의 한계를 극복하기 위해 등장한 **라이브러리**입니다. 이름에서 알 수 있듯, 작업 흐름을 선형적인 '체인(Chain)'이 아닌, **'그래프(Graph)'** 형태로 구성합니다. 이를 통해 **순환(Cycle), 분기, 조건부 실행** 등 훨씬 더 복잡하고 동적인 제어가 가능해집니다.\n",
      "\n",
      "#### LangGraph의 핵심 개념 (순서도 그리기)\n",
      "\n",
      "1.  **State (상태):** 그래프 전체에서 공유되는 '중앙 데이터 저장소'입니다. 각 단계(노드)는 이 State를 읽고, 자신의 작업 결과를 State에 업데이트합니다.\n",
      "2.  **Nodes (노드):** 그래프의 각 '작업 단위'입니다. 하나의 노드는 LLM을 호출하는 함수, 도구를 사용하는 함수 등이 될 수 있습니다. 각 노드는 현재 State를 입력받아 작업을 수행하고, 변경된 State를 반환합니다.\n",
      "3.  **Edges (엣지):** 노드와 노드를 연결하는 '화살표'입니다. LangGraph의 핵심은 **조건부 엣지(Conditional Edge)**입니다. 특정 노드의 작업 결과(State의 변화)에 따라 다음에 어떤 노드로 이동할지 동적으로 결정할 수 있습니다.\n",
      "\n",
      "#### LangGraph는 언제 사용할까요?\n",
      "\n",
      "*   **다중 에이전트 협업:** '기획자 에이전트'가 아이디어를 내면, '개발자 에이전트'가 코드를 짜고, 'QA 에이전트'가 코드를 검토하여 피드백을 주는 것과 같이 여러 에이전트가 상호작용하며 결과를 개선해야 할 때. (결과가 만족스럽지 않으면 다시 '개발자 에이전트'로 돌아가는 **순환**이 가능)\n",
      "*   **복잡한 도구 사용:** 에이전트가 여러 도구 중 어떤 것을 사용해야 할지, 혹은 도구 사용 후 결과가 만족스럽지 않을 때 다른 도구를 시도해야 할지 등 복잡한 의사결정이 필요할 때.\n",
      "*   **인간의 개입(Human-in-the-loop):** AI가 초안을 작성하면 사람이 검토하고 승인하거나 수정을 요청하는 등, 작업 흐름 중간에 사람의 확인이 필요한 경우에 매우 유용합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심 차이점 및 관계 요약\n",
      "\n",
      "| 구분 | **LangChain** | **LangGraph** |\n",
      "| :--- | :--- | :--- |\n",
      "| **제어 흐름** | **선형적, 순차적 (Directed Acyclic Graph - DAG)** | **순환적, 조건부 (Cyclic Graph)** |\n",
      "| **핵심 추상화** | **Chain (LCEL)** | **StateGraph (상태, 노드, 엣지)** |\n",
      "| **상태 관리** | 각 단계별로 출력이 다음 단계의 입력으로 전달됨 | 중앙의 `State` 객체를 통해 명시적으로 관리 및 공유 |\n",
      "| **주요 사용 사례** | RAG, 간단한 챗봇, 정해진 순서의 작업 자동화 | 다중 에이전트 시스템, 복잡한 의사결정, 인간 개입 워크플로우 |\n",
      "| **비유** | **레고 조립 설명서** | **지능적인 순서도 (Flowchart)** |\n",
      "| **관계** | LangGraph는 LangChain의 컴포넌트(LLM, Tool 등)를 **노드**로 사용하여 구축됩니다. 즉, **LangChain의 확장판**입니다. |\n",
      "\n",
      "### 결론\n",
      "\n",
      "AI 전문가로서의 조언은 다음과 같습니다.\n",
      "\n",
      "1.  **먼저 LangChain으로 시작하세요.** LLM 애플리케이션의 기본 개념과 구성 요소를 익히는 데 가장 좋은 도구입니다. 대부분의 애플리케이션은 LangChain만으로도 충분히 구현할 수 있습니다.\n",
      "2.  애플리케이션의 로직이 복잡해져 **\"만약 ~라면 B로 가고, 아니면 C로 가서 결과를 보고 다시 A로 돌아가라\"** 와 같은 순환적이고 조건적인 제어가 필요해지면, 그때 **LangGraph를 도입**하는 것을 고려하세요.\n",
      "\n",
      "결국, **LangChain은 '무엇을' 할 것인지(기능 블록)를 제공하고, LangGraph는 그 블록들을 '어떻게' 복잡하게 엮어낼 것인지(제어 로직)를 정의**하는 강력한 조합이라고 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은(는) 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-2.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
