{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "#### LangSmith 기본 예제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d96986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " name         : langsmith                                                                       \n",
      " version      : 0.4.28                                                                          \n",
      " description  : Client library to connect to the LangSmith LLM Tracing and Evaluation Platform. \n",
      "\n",
      "dependencies\n",
      " - httpx >=0.23.0,<1\n",
      " - orjson >=3.9.14\n",
      " - packaging >=23.2\n",
      " - pydantic >=1,<3\n",
      " - requests >=2.0.0\n",
      " - requests-toolbelt >=1.0.0\n",
      " - zstandard >=0.23.0\n",
      "\n",
      "required by\n",
      " - langchain requires >=0.1.17\n",
      " - langchain-community requires >=0.1.125\n",
      " - langchain-core requires >=0.3.45\n"
     ]
    }
   ],
   "source": [
    "!poetry show langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_y\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "##### LangSmith와 LangChain을 활용한 기본 로깅 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 [AI 답변]:\n",
      "LangGraph와 LangChain은 모두 언어 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크이지만, 두 프레임워크는 서로 다른 디자인 철학과 사용 사례에 중점을 둡니다.\n",
      "\n",
      "LangChain은 언어 모델을 사용하여 애플리케이션을 구축하기 위한 오픈 소스 프레임워크입니다. LangChain은 언어 모델을 중심으로构建되는 애플리케이션 개발을 단순화하기 위해 설계되었으며, 모델 통합, 워크플로우 관리 및 데이터 처리를 위한 다양한 도구와 라이브러리를 제공합니다. LangChain은 대규모 언어 모델을 사용하여 자연어 처리, 생성 및 분석과 같은 다양한 작업을 수행하는 애플리케이션을 구축하는 데 사용할 수 있습니다.\n",
      "\n",
      "LangGraph는 LangChain을 기반으로 구축된 프레임워크로, 언어 모델을 사용하여 애플리케이션을 구축하기 위한 그래프 기반의 워크플로우 관리 시스템을 제공합니다. LangGraph는 LangChain의 확장으로, 언어 모델을 사용하여 애플리케이션을 구축하는 데 필요한 워크플로우 관리, 작업 관리 및 데이터 흐름 제어를 위한 기능을 제공합니다. LangGraph는 LangChain의 기능을 확장하여 더 복잡하고 동적인 워크플로우를 관리할 수 있는 기능을 제공합니다.\n",
      "\n",
      "따라서 LangChain과 LangGraph의 주요 차이점은 다음과 같습니다:\n",
      "\n",
      "* LangChain: 언어 모델을 사용하여 애플리케이션을 구축하기 위한 기본 프레임워크로, 모델 통합, 워크플로우 관리 및 데이터 처리를 위한 도구와 라이브러리를 제공합니다.\n",
      "* LangGraph: LangChain을 기반으로 구축된 프레임워크로, 언어 모델을 사용하여 애플리케이션을 구축하기 위한 그래프 기반의 워크플로우 관리 시스템을 제공합니다.\n",
      "\n",
      "LangGraph는 LangChain의 확장으로, 더 복잡하고 동적인 워크플로우를 관리할 수 있는 기능을 제공합니다. 따라서 LangGraph는 LangChain을 사용하여 애플리케이션을 구축하는 데 필요한 더 고급 워크플로우 관리 기능을 필요로 하는 경우에 적합합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# LangSmith API Key 설정\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")  # LangSmith 활성화\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")  # API Key 불러오기\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")   # 프로젝트 이름 설정\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")   # EndPoint 설정\n",
    "\n",
    "# LLM 모델 설정 (OpenAI 사용)\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# LangSmith로 실행 추적\n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "\n",
    "    # 개별 메시지 템플릿 정의\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 유용한 AI 비서입니다.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    messages = chat_prompt.format_messages(question=question)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# 테스트 실행\n",
    "question = \"LangGraph와 LangChain의 차이점은 무엇인가요?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n🔹 [AI 답변]:\")\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
