{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_y\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"인공지능 모델의 학습 원리는 크게 '데이터 수집', '모델 설계', '학습', '평가' 네 단계로 나눌 수 있습니다.\\n\\n1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는 대량의 데이터가 필요합니다. 이 데이터는 문제의 유형에 따라 달라질 수 있습니다. 예를 들어, 이미지 분류 모델을 만들려면 이미지 데이터가 필요하고, 자연어 처리 모델을 만들려면 텍스트 데이터가 필요합니다.\\n\\n2. **모델 설계**: 수집한 데이터를 바탕으로 모델을 설계합니다. 모델 설계에는 여러 가지 방법이 있으며, 문제의 유형과 데이터의 특성에 따라 적절한 모델을 선택해야 합니다. 예를 들어, 이미지 분류 모델에는 합성곱 신경망(CNN), 자연어 처리 모델에는 순환 신경망(RNN)이나 트랜스포머 등이 있습니다.\\n\\n3. **학습**: 설계한 모델에 수집한 데이터를 입력하여 모델을 학습시킵니다. 학습 과정에서는 모델이 데이터를 분석하고, 데이터의 패턴을 학습하여 예측이나 분류를 수행할 수 있도록 합니다. 학습 과정에서는 모델의 가중치를 조정하여 모델의 성능을 개선합니다.\\n\\n4. **평가**: 학습이 완료된 모델의 성능을 평가합니다. 평가 과정에서는 모델이 학습하지 않은 새로운 데이터에 대해 예측이나 분류를 수행하고, 그 결과를 분석하여 모델의 성능을 평가합니다. 평가 결과에 따라 모델의 성능을 개선하기 위해 모델의 구조나 학습 방법을 조정할 수 있습니다.\\n\\n인공지능 모델의 학습 원리는 이와 같이 데이터 수집, 모델 설계, 학습, 평가의 네 단계로 이루어져 있습니다. 각 단계에서 적절한 방법과 기술을 선택하여 모델의 성능을 개선할 수 있습니다.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 24, 'total_tokens': 364, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.206378646, 'prompt_time': 0.000241496, 'completion_time': 0.798627106, 'total_time': 0.798868602}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-501ea130-c346-4d88-9f31-c3adb7046681', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--d7ae388c-fbc0-4fdc-bdf7-95bd1bf67b8f-0' usage_metadata={'input_tokens': 24, 'output_tokens': 340, 'total_tokens': 364, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 크게 '데이터 수집', '모델 설계', '학습', '평가' 네 단계로 나눌 수 있습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는 대량의 데이터가 필요합니다. 이 데이터는 문제의 유형에 따라 달라질 수 있습니다. 예를 들어, 이미지 분류 모델을 만들려면 이미지 데이터가 필요하고, 자연어 처리 모델을 만들려면 텍스트 데이터가 필요합니다.\n",
      "\n",
      "2. **모델 설계**: 수집한 데이터를 바탕으로 모델을 설계합니다. 모델 설계에는 여러 가지 방법이 있으며, 문제의 유형과 데이터의 특성에 따라 적절한 모델을 선택해야 합니다. 예를 들어, 이미지 분류 모델에는 합성곱 신경망(CNN), 자연어 처리 모델에는 순환 신경망(RNN)이나 트랜스포머 등이 있습니다.\n",
      "\n",
      "3. **학습**: 설계한 모델에 수집한 데이터를 입력하여 모델을 학습시킵니다. 학습 과정에서는 모델이 데이터를 분석하고, 데이터의 패턴을 학습하여 예측이나 분류를 수행할 수 있도록 합니다. 학습 과정에서는 모델의 가중치를 조정하여 모델의 성능을 개선합니다.\n",
      "\n",
      "4. **평가**: 학습이 완료된 모델의 성능을 평가합니다. 평가 과정에서는 모델이 학습하지 않은 새로운 데이터에 대해 예측이나 분류를 수행하고, 그 결과를 분석하여 모델의 성능을 평가합니다. 평가 결과에 따라 모델의 성능을 개선하기 위해 모델의 구조나 학습 방법을 조정할 수 있습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 이와 같이 데이터 수집, 모델 설계, 학습, 평가의 네 단계로 이루어져 있습니다. 각 단계에서 적절한 방법과 기술을 선택하여 모델의 성능을 개선할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content=\"인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 많이 보여주면서 '이것은 고양이야', '이것은 강아지야'라고 알려주면, 모델은 이 사진들의 특징을 분석하기 시작합니다.\\n\\n고양이 사진에는 고양이의 특징인 귀가 있고, 강아지 사진에는 강아지 귀가 있습니다. 모델은 이 특징들을 학습하면서 고양이와 강아지를 구분하는 기준을 만듭니다.\\n\\n이렇게 모델이 학습하는 과정을 수식으로 나타내면, 다음과 같습니다.\\n\\n1. **데이터 수집**: 많은 양의 데이터(고양이와 강아지의 사진)를 수집합니다.\\n2. **데이터 전처리**: 데이터를 컴퓨터가 처리할 수 있는 형태로 변환합니다.\\n3. **모델 정의**: 모델의 구조를 정의합니다. (예: 신경망)\\n4. **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. (예: 크로스 엔트로피)\\n5. **최적화 알고리즘 선택**: 모델의 가중치를 업데이트하는 최적화 알고리즘을 선택합니다. (예: 경사 하강법)\\n6. **학습**: 모델을 학습합니다. (예: 고양이/강아지 분류)\\n\\n학습 과정에서는 모델의 가중치를 업데이트하면서 손실 함수를 최소화하는 방향으로 학습합니다. 이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 강아지인지 분류할 수 있습니다.\\n\\n이러한 학습 원리는 다양한 인공지능 모델에 적용할 수 있으며, 모델의 성능을 높이는데 중요한 역할을 합니다.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 365, 'prompt_tokens': 36, 'total_tokens': 401, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.204232015, 'prompt_time': 0.000520512, 'completion_time': 0.85538572, 'total_time': 0.855906232}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-ba7fbc78-b857-4609-8009-83b36754ed67', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--40b89a02-91a2-4524-9efe-1b94d6fbb75c-0' usage_metadata={'input_tokens': 36, 'output_tokens': 365, 'total_tokens': 401, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 많이 보여주면서 '이것은 고양이야', '이것은 강아지야'라고 알려주면, 모델은 이 사진들의 특징을 분석하기 시작합니다.\n",
      "\n",
      "고양이 사진에는 고양이의 특징인 귀가 있고, 강아지 사진에는 강아지 귀가 있습니다. 모델은 이 특징들을 학습하면서 고양이와 강아지를 구분하는 기준을 만듭니다.\n",
      "\n",
      "이렇게 모델이 학습하는 과정을 수식으로 나타내면, 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 많은 양의 데이터(고양이와 강아지의 사진)를 수집합니다.\n",
      "2. **데이터 전처리**: 데이터를 컴퓨터가 처리할 수 있는 형태로 변환합니다.\n",
      "3. **모델 정의**: 모델의 구조를 정의합니다. (예: 신경망)\n",
      "4. **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. (예: 크로스 엔트로피)\n",
      "5. **최적화 알고리즘 선택**: 모델의 가중치를 업데이트하는 최적화 알고리즘을 선택합니다. (예: 경사 하강법)\n",
      "6. **학습**: 모델을 학습합니다. (예: 고양이/강아지 분류)\n",
      "\n",
      "학습 과정에서는 모델의 가중치를 업데이트하면서 손실 함수를 최소화하는 방향으로 학습합니다. 이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 강아지인지 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용할 수 있으며, 모델의 성능을 높이는데 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주며 \"이건 고양이야\", \"이건 강아지야\"라고 말해주는 겁니다. 모델은 이 데이터를 통해 고양이와 강아지를 구별하는 법을 배웁니다.\n",
      "\n",
      "구체적으로는 다음과 같은 과정으로 학습합니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 많은 양의 데이터가 필요합니다. 이 데이터는 문제에 따라 달라지는데, 예를 들어 이미지 분류 문제라면 고양이와 강아지의 사진이 필요할 것입니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있도록 가공하는 과정입니다. 이 과정에서는 데이터의 품질을 높이고, 데이터를 정규화하거나 변환하는 작업이 포함될 수 있습니다.\n",
      "\n",
      "3. **모델 선택**: 어떤 유형의 인공지능 모델을 사용할지 결정합니다. 예를 들어, 이미지 분류 문제라면 합성곱 신경망(CNN)과 같은 모델을 선택할 수 있습니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 모델이 데이터를 분석하여 결과를 예측합니다. 예측 결과와 실제 값 사이의 차이를 손실 함수(loss function)로 계산합니다. 이 손실 함수를 최소화하는 방향으로 모델의 가중치를 조정하는 과정을 반복합니다. 이 과정을 통해 모델은 데이터를 통해 학습하고, 성능을 개선합니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 평가 데이터 세트를 사용하여 모델의 예측 성능을 측정하고, 필요에 따라 모델을 수정하거나 추가 학습을 진행합니다.\n",
      "\n",
      "예를 들어, 간단한 예를 들어보겠습니다. 만약 우리가 사과와 바나나의 이미지를 분류하는 모델을 만들고 싶다고 가정해 봅시다. \n",
      "\n",
      "- **데이터 수집**: 우리는 사과와 바나나의 사진 여러 장을 수집합니다.\n",
      "- **데이터 전처리**: 각 사진을 적절한 크기로 자르고, 비슷한 크기로 변환합니다.\n",
      "- **모델 선택**: 우리는 이 작업에 적합한 신경망 모델을 선택합니다.\n",
      "- **학습**: 모델에 사진을 보여주고, 어떤 사진은 사과라고, 어떤 사진은 바나나라고 알려줍니다. 처음에는 모델이 정확하게 분류하지 못하지만, 점점 더 많은 데이터를 통해 학습하면서 사과와 바나나를 구별하는 법을 배웁니다.\n",
      "- **평가**: 다른 사진들을 모델에 입력하여 사과인지 바나나인지 분류하게 하고, 실제와 맞는지 확인합니다.\n",
      "\n",
      "이처럼 인공지능 모델은 다양한 데이터를 통해 학습하고, 그 학습을 통해 새로운, 보지 못한 데이터에 대해서도 예측하거나 분류하는 능력을 키웁니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "사람이 경험을 통해 배우고 기억하는 것처럼, 인공지능 모델도 데이터를 통해 학습합니다. 인공지능 모델이 학습하는 과정을 단계별로 설명하면 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는大量的 데이터가 필요합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다. 예를 들어, 고양이와 개 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 경우, 고양이와 개 사진 데이터 셋을 수집해야 합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델이 학습할 수 있는 형태로 변환되어야 합니다. 이 과정에는 데이터 정리, 변환, 노이즈 제거 등이 포함됩니다.\n",
      "\n",
      "3. **모델 선택**: 인공지능 모델에는 여러 가지 유형이 있습니다. 문제의 성격에 따라 적합한 모델을 선택해야 합니다. 예를 들어, 이미지 분류 문제에는 합성곱 신경망(CNN), 자연어 처리 문제에는 순환 신경망(RNN)이나 트랜스포머 모델이 적합합니다.\n",
      "\n",
      "4. **모델 학습**: 선택된 모델에 데이터를 입력하여 모델의 파라미터를 조정합니다. 이 과정에서는 모델이 예측한 결과와 실제 결과 사이의 오류를 최소화하는 것을 목표로 합니다. 오류를 최소화하기 위해 모델은 예측 결과와 실제 결과의 차이인 **손실 함수(loss function)**를 계산하고, 이 손실 함수를 최소화하는 방향으로 파라미터를 조정합니다. 이 과정은 **최적화 알고리즘**을 통해 이루어집니다.\n",
      "\n",
      "5. **평가**: 학습된 모델의 성능을 평가합니다. 이를 위해 학습에 사용되지 않은 별도의 테스트 데이터를 사용합니다. 평가 지표에는 정확도, 정밀도, 재현율, F1 점수 등이 있습니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능이 만족할 만한 수준에 도달하지 않았다면, 모델의 구조, 하이퍼파라미터 조정, 데이터 전처리 방법 변경 등을 통해 모델을 개선하는 과정을 거칩니다.\n",
      "\n",
      "예를 들어, 어린아이가 고양이를 인식하는 법을 배우는 과정을 생각해 봅시다. 처음에 아이는 고양이를 본 적이 없어서 고양이가 무엇인지 모릅니다. 그런데 부모님이 여러 장의 고양이 사진을 보여 주고 \"이건 고양이야\"라고 말해 주면, 아이는 고양이에 대해 조금씩 배웁니다. 이 과정을 반복하면서, 아이는 고양이의 특징(예: 고양이는 귀가 있고, 털이 있고, 꼬리가 있다)을 스스로 터득하게 됩니다. 인공지능 모델의 학습 원리도 이와 유사합니다. 모델이 다양한 데이터를 통해 스스로 규칙이나 패턴을 발견하고, 그것에 따라 고양이 또는 개 사진을 분류하는 법을 배우는 것입니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약 (정상동작 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**추천 영화: <그린 마일 (The Green Mile, 1999) – 드라마 / 판타지**\n",
      "\n",
      "**왜 추천하는지 간단히 소개할게요**\n",
      "\n",
      "| 항목 | 내용 |\n",
      "|---|---|\n",
      "| **감독** | 프랭크 다라본트 (Frank Darabont) |\n",
      "| **주연** | 톰 행크스, 마이클 클라크 딘, 데이비드 모스 |\n",
      "| **줄거리** | 1930년대 미국, 사형수들이 수감된 ‘그린 마일’이라는 사형수 대기실에서 일어나는 인간과 초자연적인 존재와의 교감 이야기를 그린다. 주인공 ‘폴’(톰 행크스)은 사형수들의 인간적인 면모와, 신비로운 힘을 가진 ‘존 코피’(마이클 클라크 딘)의 이야기를 통해 정의, 용서, 희생이라는 무게감 있는 주제를 탐구한다. |\n",
      "| **드라마 포인트** | * **인물 중심 서사** – 각 인물의 사연과 감정이 섬세하게 묘사돼 관객이 깊이 공감한다.<br>* **감동적인 인간애** – 억압받는 상황 속에서도 드러나는 따뜻함과 연민이 강렬한 여운을 남긴다.<br>* **윤리·도덕적 질문** – 사형제도, 정의, 인간의 선과 악을 고민하게 만든다.<br>* **감동적인 연출·음악** – 존 윌리엄스의 스코어와 다라본트 감독 특유의 서정적인 연출이 감동을 배가한다. |\n",
      "| **특징** | - 원작 소설(스티븐 킹)과 비교해도 충실한 각색<br>- 톰 행크스와 마이클 클라크 딘의 뛰어난 연기력<br>- 1시간 30분 정도의 적당한 러닝타임으로 몰입도가 높다 |\n",
      "| **추천 포인트** | * **감동을 원한다면** → 눈물과 동시에 인간 본성에 대한 사색을 제공한다.<br>* **배우들의 연기를 즐기고 싶다면** → 톰 행크스와 마이클 클라크 딘의 케미가 빛난다.<br>* **깊은 메시지를 찾는다면** → ‘정의’와 ‘용서’라는 보편적 주제가 오래도록 기억에 남는다. |\n",
      "\n",
      "---\n",
      "\n",
      "### 한 줄 요약\n",
      "> *‘그린 마일’은 사형수 대기실이라는 무거운 배경 속에서 인간의 선함과 구원의 가능성을 섬세히 그린 감동적인 드라마 영화다.*  \n",
      "\n",
      "한 번 감상해 보시면, 눈물과 함께 인간 존재에 대한 따뜻한 통찰을 얻을 수 있을 거예요. 🎬🍿\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "      model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " The  Notebook \n",
      "\n",
      "*   **감독** : 닉  카사베츠 \n",
      "*   **캐스팅** : 라이언 고슬링  , 레이철 맥애덤스 \n",
      "*   **줄거리** : '노트북'은 니콜라스 스파크스의 소설을 원작으로 하는 영화입니다. 이 영화는1940년대와1990년대의 두 시기에 걸쳐 사랑과 인생의 복잡성을 다루고 있습니다. 노아(라이언 고슬링)와 앨리(레이철 맥애덤스)는 여름 캠프에서 처음 만나 사랑에 빠지게 됩니다. 하지만 앨리의 부모는 노아의 사회적 지위가 낮다는 이유로 두 사람의 사랑을 반대합니다. 이에 앨리는 노아와의 만남을 중단하고, 노아는 앨리를 잊지 않기 위해365일간 매일 편지를 보냅니다. 앨리는 다른 남자와 약혼하지만, 노아와의 추억을 잊지 못합니다. 마침내 앨리는 노아의 편지를 읽고, 노아를 찾아가게 됩니다. 두 사람은 다시 만나 사랑을 재확인하고, 앨리는 노아와의 약속을 지키기 위해 노아와 결혼합니다. 이 영화는 사랑, 희생, 그리고 인생의 기쁨과 슬픔을 다루고 있습니다. 아름다운 영상과 감동적인 이야기로 많은 사랑을 받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('그린 마일 (The Green Mile)\\n'\n",
      " '\\n'\n",
      " '제목: **그린 마일 (The Green Mile)**  \\n'\n",
      " '감독: **프랭크 다라본트**  \\n'\n",
      " '캐스팅: **톰 행크스**(폴 에지콤), **마이클 클라크·던컨**(존 코피), **데이비드 모스**(브루스 웨인), **보니 '\n",
      " '헌터**(레베카 스미스) 등  \\n'\n",
      " '줄거리: 1935년 미국 남부 교도소 ‘그린 마일’에서 사형수 존 코피(마이클 클라크·던컨)는 신비한 치유 능력을 가진 어린 소년 '\n",
      " '에이미와 만나게 된다. 코피의 초자연적인 힘은 교도소 안의 간수와 수감자들의 삶에 기적 같은 변화를 일으키며, 인간의 선과 악, 정의와 '\n",
      " '연민에 대한 깊은 질문을 던진다. 폴 에지콤(톰 행크스)과 동료 간수들은 코피와의 교감을 통해 인간성의 빛과 어두움을 동시에 마주하게 '\n",
      " '된다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
